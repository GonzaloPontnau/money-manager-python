# ü§ñ FinBot ‚Äî Asistente Financiero con IA

FinBot es un chatbot conversacional integrado en Money Manager que permite a los usuarios consultar su informaci√≥n financiera usando lenguaje natural. Utiliza una arquitectura **RAG (Retrieval-Augmented Generation)** para combinar datos reales del usuario con la capacidad generativa de un LLM.

---

## Caracter√≠sticas

- üí¨ **Conversaci√≥n natural** en espa√±ol e ingl√©s (detecci√≥n autom√°tica de idioma)
- üìä **Consultas financieras** sobre balance, gastos, ingresos, presupuestos y transferencias
- üîç **B√∫squeda sem√°ntica** de transacciones usando embeddings vectoriales
- üß† **Contexto financiero en tiempo real** inyectado en cada consulta
- üîÑ **Follow-up inteligente** cuando la consulta necesita m√°s detalle
- üíæ **Historial de conversaci√≥n** persistente por sesi√≥n
- ü´ß **Widget flotante** no intrusivo en todas las p√°ginas

---

## Arquitectura RAG

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Usuario    ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Intent Detector  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Follow-up?     ‚îÇ
‚îÇ  (mensaje)   ‚îÇ    ‚îÇ  (regex-based)   ‚îÇ    ‚îÇ  S√≠ ‚Üí respuesta ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ  No ‚Üí continuar  ‚îÇ
                                           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                    ‚îÇ
                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   Contexto Financiero    ‚îÇ  ‚Üê Django ORM queries
    ‚îÇ   (balance, gastos,      ‚îÇ
    ‚îÇ    presupuestos, etc.)   ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
                   ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   Embedding del mensaje  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Qdrant Search   ‚îÇ
    ‚îÇ   (HuggingFace API)      ‚îÇ    ‚îÇ  (top-5 similar) ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                             ‚îÇ
                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   System Prompt +        ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Groq LLM      ‚îÇ
    ‚îÇ   Contexto + RAG +       ‚îÇ    ‚îÇ   (respuesta)    ‚îÇ
    ‚îÇ   Historial conversaci√≥n ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ
                                             ‚ñº
                                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                    ‚îÇ Respuesta final  ‚îÇ
                                    ‚îÇ al usuario       ‚îÇ
                                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Componentes

### 1. RAG Pipeline (`services/rag_pipeline.py`)

Orquestador principal. Recibe un mensaje del usuario y coordina todos los pasos:

1. **Guarda** el mensaje del usuario en `ConversationMessage`
2. **Carga** el historial de conversaci√≥n (√∫ltimos N mensajes)
3. **Detecta intenci√≥n** y eval√∫a si necesita follow-up
4. **Construye contexto financiero** desde las queries de Django
5. **Genera embedding** del mensaje y busca transacciones similares en Qdrant
6. **Ensambla el prompt** con contexto + resultados RAG + historial
7. **Llama al LLM** y guarda la respuesta

### 2. Intent / Follow-up Detector (`services/followup_detector.py`)

Detecta la intenci√≥n del usuario usando patrones de keywords y determina si se necesita una pregunta de follow-up:

| Intenci√≥n            | Keywords (ejemplo)                 | Requiere            |
| -------------------- | ---------------------------------- | ------------------- |
| `balance_check`      | "saldo", "balance", "cu√°nto tengo" | ‚Äî                   |
| `spending_query`     | "gastos", "cu√°nto gast√©"           | Per√≠odo temporal    |
| `category_query`     | "categor√≠a", "en qu√© gasto"        | Per√≠odo temporal    |
| `budget_status`      | "presupuesto", "l√≠mite"            | ‚Äî                   |
| `transaction_search` | "buscar", "transacci√≥n"            | Detalle de b√∫squeda |
| `income_query`       | "ingreso", "salario"               | ‚Äî                   |
| `transfer_query`     | "transferencia", "envi√©"           | ‚Äî                   |

Si la consulta requiere informaci√≥n que no est√° presente (ej: "¬øcu√°nto gast√©?" sin per√≠odo), el sistema genera una pregunta de follow-up con opciones clickeables.

### 3. Financial Context Builder (`services/financial_context.py`)

Construye un resumen textual del estado financiero del usuario que se inyecta en el prompt del LLM:

- **Balance actual** (ingresos totales - gastos totales)
- **Gastos del mes** desglosados por categor√≠a
- **Estado de presupuestos** (porcentaje usado, excedidos)
- **√öltimas 10 transacciones**
- **Categor√≠as del usuario** (ingreso y gasto)

### 4. Embedding Service (`services/embedding_service.py`)

Cliente de la API de Inferencia de HuggingFace para generar embeddings con el modelo `sentence-transformers/all-MiniLM-L6-v2` (384 dimensiones).

### 5. Qdrant Service (`services/qdrant_service.py`)

Gestiona la base de datos vectorial Qdrant:

- **`ensure_collection()`** ‚Äî Crea la colecci√≥n si no existe
- **`upsert_transaction()`** ‚Äî Inserta/actualiza un vector con payload financiero
- **`delete_point()`** ‚Äî Elimina un vector cuando se borra una transacci√≥n
- **`search_similar()`** ‚Äî B√∫squeda sem√°ntica filtrada por usuario (cosine similarity)

> **Payload almacenado por cada transacci√≥n:**
> `user_id`, `tipo`, `monto`, `categoria`, `descripcion`, `fecha`

### 6. LLM Service (`services/llm_service.py`)

Cliente de la API de Groq (compatible con formato OpenAI chat completions):

- Modelo configurable v√≠a `GROQ_MODEL`
- Temperature: 0.3 (respuestas focalizadas)
- Max tokens: 1024 (configurable)
- Timeout: 25 segundos

### 7. System Prompt (`prompts/system_prompts.py`)

El prompt del sistema instruye al LLM a:

- Responder en el **mismo idioma** que el usuario
- Usar **√∫nicamente** los datos financieros proporcionados
- Formatear montos con `$` y dos decimales
- Ser conciso y usar bullet points
- Redirigir amablemente consultas no financieras

---

## Auto-Embedding v√≠a Signals

Cuando una transacci√≥n se crea, edita o elimina, los **signals de Django** autom√°ticamente:

```python
# chatbot/signals.py

@receiver(post_save, sender=Transaccion)
def embed_transaction_on_save(sender, instance, **kwargs):
    text = _generate_transaction_text(instance)  # "Gasto de $150 en Compras el 14/02/2026"
    embedding = get_embedding(text)               # ‚Üí vector 384-dim
    upsert_transaction(instance, embedding)       # ‚Üí Qdrant

@receiver(post_delete, sender=Transaccion)
def remove_transaction_embedding(sender, instance, **kwargs):
    delete_point(instance.id)                     # ‚Üí elimina de Qdrant
```

Esto garantiza que el vector store est√° **siempre sincronizado** con la base de datos relacional.

---

## Modelo de Datos

```python
class ConversationMessage(Model):
    usuario       = ForeignKey(User)       # Propietario
    session_id    = CharField(max_length=64)# Agrupa mensajes en conversaciones
    role          = CharField()             # 'user' | 'assistant' | 'system'
    content       = TextField()             # Contenido del mensaje
    is_followup_question = BooleanField()   # ¬øEs pregunta de follow-up?
    created_at    = DateTimeField()         # Timestamp
```

---

## API Endpoints

| M√©todo | Endpoint                                    | Descripci√≥n                        |
| ------ | ------------------------------------------- | ---------------------------------- |
| `POST` | `/chatbot/api/chat/send/`                   | Enviar mensaje y recibir respuesta |
| `GET`  | `/chatbot/api/chat/history/?session_id=...` | Obtener historial de una sesi√≥n    |
| `POST` | `/chatbot/api/chat/new/`                    | Iniciar nueva conversaci√≥n         |

Ver [API.md](API.md) para detalles completos.

---

## Frontend ‚Äî Widget Flotante

El widget se compone de:

- **Template**: `templates/chatbot/chatbot_widget.html` ‚Äî inyectado con template tag `{% chatbot_widget %}`
- **CSS**: `static/css/chatbot.css` ‚Äî design system con tokens `--cb-*` vinculados a los globals
- **JS**: `static/js/chatbot.js` ‚Äî IIFE con gesti√≥n de estado, DOM y fetch API

### Flujo UI

1. **Burbuja flotante** fija en esquina inferior derecha
2. Click ‚Üí **panel de chat** se abre con animaci√≥n
3. **Suggestion chips** para consultas r√°pidas ("Mi balance", "Gastos del mes", "Presupuestos")
4. √Årea de mensajes con burbujas diferenciadas usuario/asistente
5. **Indicador de escritura** animado mientras procesa
6. **Follow-up buttons** cuando el bot necesita m√°s informaci√≥n
7. Bot√≥n **nueva conversaci√≥n** para resetear sesi√≥n

---

## Configuraci√≥n

Variables de entorno requeridas en `.env`:

```env
GROQ_API_KEY=gsk_xxxxx          # API key de Groq
GROQ_MODEL=openai/gpt-oss-120   # Modelo LLM (opcional)
QDRANT_URL=https://xxx.qdrant.io # URL del cluster Qdrant
QDRANT_API_KEY=xxxxx             # API key de Qdrant
HF_API_TOKEN=hf_xxxxx           # Token de HuggingFace
```

Par√°metros en `settings.py`:

```python
CHATBOT_MAX_HISTORY = 10   # Mensajes de historial enviados al LLM
CHATBOT_MAX_TOKENS = 1024  # Max tokens en respuesta del LLM
```
